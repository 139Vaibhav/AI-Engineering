{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b968061f-5c24-461c-a78f-cbc9a256b7ae",
   "metadata": {},
   "source": [
    "# HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e266092-ff24-41cf-b41d-ceeb1e7d3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06cd74a0-5559-417f-b9d1-4830243baeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95c2ef2a-0f9b-4ec8-8781-41ed22d7ce80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997096657752991}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classifier(\"I'm so excited to be learning about large language models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b26f48-92b4-4701-86b1-1f67b228d8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d7d1fed2c74e25a17093cb795e5643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6351579569ac4e0e9175e4145ff89b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ee82c4ccd74cbfaf38811716c7e84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95df29e07e0544ec8bbcba9926db6155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce9ab50bb7a42e0aba2a05f08a30078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb3a5467fe645bab734dd79e634bace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model=\"dslim/bert-base-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b223959-8a56-49db-869c-7df219581070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.9954881,\n",
       "  'index': 4,\n",
       "  'word': 'Anna',\n",
       "  'start': 12,\n",
       "  'end': 16},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99960667,\n",
       "  'index': 9,\n",
       "  'word': 'New',\n",
       "  'start': 34,\n",
       "  'end': 37},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9993955,\n",
       "  'index': 10,\n",
       "  'word': 'York',\n",
       "  'start': 38,\n",
       "  'end': 42},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9995803,\n",
       "  'index': 11,\n",
       "  'word': 'City',\n",
       "  'start': 43,\n",
       "  'end': 47},\n",
       " {'entity': 'B-ORG',\n",
       "  'score': 0.9957462,\n",
       "  'index': 13,\n",
       "  'word': 'Morgan',\n",
       "  'start': 52,\n",
       "  'end': 58},\n",
       " {'entity': 'I-ORG',\n",
       "  'score': 0.9979346,\n",
       "  'index': 14,\n",
       "  'word': 'Stanley',\n",
       "  'start': 59,\n",
       "  'end': 66}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"Her name is Anna and she works in New York City for Morgan Stanley\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3e0de8-d50a-4123-b845-e30ae6ad24ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b731b2c8c3c4a3e9788f6bdfdb44f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa9d404569b405eb9c8ecb00140a1a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9799a6f709b64b0e9cbcc01f7f439faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb007ddee714331af2756b0653296b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28f49973c1c412894b50aab4bc5662e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5013264859074ed480b001981c309530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "zeroshot_classification = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77273115-f5bd-4ccb-b711-5dfb2d6d3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_classify = \"one day I will see the world\"\n",
    "candidate_labels = ['travel', 'cooking', 'dancing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4e8516-bc16-4b14-9998-a7d37a03e2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'one day I will see the world',\n",
       " 'labels': ['travel', 'dancing', 'cooking'],\n",
       " 'scores': [0.9938650727272034, 0.003273784415796399, 0.0028610362205654383]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_classification(sequence_to_classify, candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff40559-65a1-432f-8943-13169512c343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I wanna be the CEO of a big-wig firm',\n",
       " 'labels': ['ambition',\n",
       "  'work',\n",
       "  'love for work',\n",
       "  'travel',\n",
       "  'cooking',\n",
       "  'dancing',\n",
       "  'love'],\n",
       " 'scores': [0.8262977004051208,\n",
       "  0.08831699937582016,\n",
       "  0.07176921516656876,\n",
       "  0.004037776030600071,\n",
       "  0.0032555668149143457,\n",
       "  0.0031692718621343374,\n",
       "  0.0031534992158412933]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing on another sentence\n",
    "sentence2 = \"I wanna be the CEO of a big-wig firm\"\n",
    "labels = ['travel', 'cooking', 'dancing', 'ambition', 'love', 'work', 'love for work']\n",
    "zeroshot_classification(sentence2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba427b-e1ea-47e8-9615-853e5548d9e1",
   "metadata": {},
   "source": [
    "# Pre-trained tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45639cc9-aff1-4b02-92e1-6c0faeb9accf",
   "metadata": {},
   "source": [
    "## bert-base-uncased Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12a8f245-6de3-4146-bd1d-a9aec2b7422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a762a3ba-20b1-4881-b57c-f96c0003d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfe8fb87-3abf-405e-8db7-f761bca6ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b370e4f9-dcbb-45b5-a753-949ca632f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"I'm so excited to learn about large language models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ac68f86-166d-4f76-ab4e-86ad3ae14b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1045, 1005, 1049, 2061, 7568, 2000, 4553, 2055, 2312, 2653, 4275, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(sentence)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aa0e5e2-db36-47b1-a07d-b3d327ce9eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', \"'\", 'm', 'so', 'excited', 'to', 'learn', 'about', 'large', 'language', 'models']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43a65b06-80d4-4592-8690-2156c207a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1045, 1005, 1049, 2061, 7568, 2000, 4553, 2055, 2312, 2653, 4275]\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7602af1-981d-48ea-9422-08cf8cbd3138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i ' m so excited to learn about large language models\n"
     ]
    }
   ],
   "source": [
    "decoded_ids = tokenizer.decode(token_ids)\n",
    "print(decoded_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cd1b1a7-39f2-4956-b29b-e15eec58deae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f55aa77b-ad11-40bf-a7ee-29229e3b1e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(102)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cb610-3130-4c6f-8513-97602d720d8d",
   "metadata": {},
   "source": [
    "## xlnet-base-cased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5d25e1d-e0f4-406f-ad3b-fc02fd4cdfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = \"xlnet-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef02df9f-f6be-4eec-9c33-1c09ba8794fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c42009c0f4480c931ce88249eaaca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ba6753977a4b4b905da0a73713c67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8adc60ebac4b0bb2d928285df8d2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer2 = AutoTokenizer.from_pretrained(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6d35a52-42d8-4bcf-a377-c285dc1ec515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [35, 26, 98, 102, 5564, 22, 1184, 75, 392, 1243, 2626, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer2(sentence)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd64046a-3c4e-4299-b8f7-4da3f0678116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', \"'\", 'm', '▁so', '▁excited', '▁to', '▁learn', '▁about', '▁large', '▁language', '▁models']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer2.tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efffe693-ee18-409f-98ed-f624afe451ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Court Clinton includes broketie entered thank www Soviet super Labor\n"
     ]
    }
   ],
   "source": [
    "decoded_ids = tokenizer2.decode(token_ids)\n",
    "print(decoded_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d793f11-456d-4690-a5d5-eda41e2c33fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 26, 98, 102, 5564, 22, 1184, 75, 392, 1243, 2626]\n"
     ]
    }
   ],
   "source": [
    "token_ids = tokenizer2.convert_tokens_to_ids(tokens)\n",
    "print(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45b9eab3-13fd-47d5-8f54-fb6ece71795a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so excited to learn about large language models\n"
     ]
    }
   ],
   "source": [
    "decoded_ids = tokenizer2.decode(token_ids)\n",
    "print(decoded_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9db2fe94-2e02-4a41-a7ef-d9bc2c9314f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sep>'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer2.decode(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "513633f8-74fd-4467-b79b-a4325f69ee89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<cls>'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer2.decode(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd19af36-b9ce-4c86-9c18-1239d86f0d5f",
   "metadata": {},
   "source": [
    "## CLS = classification\n",
    "## SEP = separator\n",
    "\n",
    "- cls is placed at the beginning and sep is placed at the last\n",
    "- They are used in classification and sentence pair classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad440bf-de36-478b-875c-2da9f7935df2",
   "metadata": {},
   "source": [
    "## MASK\n",
    "- Used in tasks related to masked language modelling or text generation with a blank to fill in\n",
    "- example - \"Hello I'm a [MASK] model.\"\n",
    "    - This can give multiple results for mask like (fashion model, super model, new model, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf21b7-0b83-444c-9dfd-1cb2a89ed977",
   "metadata": {},
   "source": [
    "## Task specific tokens\n",
    "- We may need custom tokens like [SOURCE] and [TARGET] to help guide the model's behaviour during translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05f62e-3557-479d-98b4-fd0332a27c94",
   "metadata": {},
   "source": [
    "## Special tokens for padding and truncation\n",
    "- When multiple sentences off varying lengths are fed into the model, special tokens for padding may be needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb2f46-ee04-4a13-afda-d1603c99f8c2",
   "metadata": {},
   "source": [
    "# HuggingFace and Pytorch/Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e7da222-13e4-474e-be3d-a45a895ab4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab117f4b-ddfc-40df-be15-f691d3594cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so excited to learn about large language models\n",
      "{'input_ids': [35, 26, 98, 102, 5564, 22, 1184, 75, 392, 1243, 2626, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ee9acd0-51fa-45bd-ae8a-87b94e664112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6682a2871b9a4d149e839c9c66133499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc226c6683c4b93942fc204ac17f5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6cab7034b2645bf980ac720ba8c8e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d19ed769-9e6f-4c20-a79a-d3a5a544e0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 1005, 1049, 2061, 7568, 2000, 4553, 2055, 2312, 2653, 4275,\n",
      "          102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "input_ids_pt = tokenizer(sentence, return_tensors = \"pt\")\n",
    "print(input_ids_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f531c39-7f2b-4130-a036-43dac738e359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0486228edc2449dabb60fbd2f692fbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6acd26aa-59b0-4da4-b6d5-03bcb6e9baff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(**input_ids_pt).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4652fe-9ab0-4b47-a2d5-5f9006dec2f0",
   "metadata": {},
   "source": [
    "# Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855552c9-6438-404d-8f10-9b94e118cdcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course_env",
   "language": "python",
   "name": "nlp_course_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
